## 实验记录

### 2019年10月20日
讨论数据集的提取和划分。

#### 主体内容：
1. patch的中心点是在pos中心点附近的86范围内。波动范围设置为86的原因：596是pos的最大宽/高的值，为了防止pos部分出现在patch外面，而假设我们patch的宽高是768，那么中心波动范围就是（768-596）/2=86。
2. 当pos与patch有IOU相交0.6以上时，这个相交pos会被截取在patch内部的区域作为新的pos区域，但是在后续patch滑动获取新数据框时，不会滑动到这个pos的中心点了。0.6的设置是个主观假设，但有可能出现细胞核出现在patch外的0.4相交区域，这种情况可能会引入误差，因为0.6的相交区域也有可能不能全面判断该细胞是否异常。目前暂时设置0.6，后续根据模型表现再看是否进行调整。
3. 在patch与pos相交情况中，有可能出现某pos很大，例如1000，相交面积只有300，IOU百分比小于0.6，可是当前相交区域比最小pos面积256还要大，那么既然最小pos的256面积也能判断是否异常，则300的相交面积也有可能判断出是否异常，那么这边就得考虑绝对相交面积的，因此在gen_patch里有加入条件，如果相交区域大于171（最小pos面积256x0.6=171）,那么该pos相交区域裁剪后加入patch，而但由于这个情况发生在pos整体面积大的情况下，所以相交区域外的pos内容也具有价值，这样后续patch滑动时还是要考虑这个pos的。
4. 数据划分暂定：0.7/0.15/0.15，负样本在neg上随机获取，负样本数量=正样本数量=4896。
5. 数据集EDA结果：  
    (1) ROI总数：1212  
    (2) POS总数：6549  
    (3) 平均每个ROI里POS的数量：5.4  
    (4) 平均每张图里ROI的数量：2.4  
    (5) 平均每张图里POS的数量：13.1  
    (6) ROI的平均宽和高：5344，4796  
    (7) POS的平均宽和高：122，121  
    (8) POS最小的宽和高：17，15  
    (9) POS最大的宽和高：596，577  
    (10) POS最小面积：285  
    (11) POS最大面积：278114
    
#### 实质性结果：
1. 数据下载、读取和EDA
2. 数据集转化适合模型输入的数据集
3. 数据集划分

#### 后续需要留意：
1. IOU的百分比0.6。如果需要提高阈值，绝对相交区域大小条件的171也得相应修改。
2. 如果需要数据增强，波动范围86可以利用起来。
3. 某张图异常细胞是相比很深的，结果另外一张图染色很深，模型会不会错检测？染色放置时间不同意导致染色深度不一致问题是否对准确率影响大？  
    
    
### 2019年11月3日

#### 主体内容：
1. Faster-RCNN实验1主要是研究**输出结果的置信阀值**，在LeaderBoard的结果如下：

|Hyperparameter|Score|mAP@0.3|mAP@0.5|
|:---:|:---:|:---:|:---:|
|conf_0.9|0.0967|0.1045|0.0888|
|conf_0.5|0.1010|0.1097|0.0922|
|conf_0.3|0.1014|0.1103|0.0924|

总结：建议在输出结果形成json结果文件时，**考虑置信值（即分类为阳性的概率）在0.5以上的检测框**，虽然置信阀值为0.3时还会使Score高点，但是可以忽略不计，同时置信阀值过低也会导致写入过多候选框，比较耗费时间。Faster-RCNN实验1在使用5个进程同时预测结果得耗费10小时多。  
2. 在第一次数据集获取手段上，我们使用了全局pos的最大宽/高的值来计算patch中心点的波动范围，但是模型可能存在识别这种波动模式的可能，在预测中可能偏好于距输入图片中心点有86波动范围内的细胞作为阳性细胞。因此打算在每次随机patch点，单独考虑当前pos的宽/高情况，这样获取到的数据集具有更好的随机性。  
  
  
### 2019年11月5日

#### 官方宫颈癌天池比赛赛题讲解 主体内容：
1. 11月20日之前要队伍合并。
2. 数据由三名专家标注，数据标注尽量是统一。而且数据（pos/neg）的分布尽量是平衡的，不会特别悬殊。
3. kdfReader使用多线程下，要每个线程下独立实例化 read = kfbReader.reader()。
4. 评测系统担心选手给了很多的bboxes,所以设置score_threshould=0.05，max_detection=500。系统会划分出一些ROI，然后在ROI内根据前面两个指标过滤掉多余的bboxes来进行最终评测。
5. 目标检测算法总览：  
[object_detection_overview图](https://github.com/AlvinAi96/WSI_Detection/blob/master/README_IMG/object_detection_overview.jpg)
[目标检测算法总览](https://github.com/jiajunhua/hoya012-deep_learning_object_detection)  
[baseline模型RetinaNet图](https://github.com/AlvinAi96/WSI_Detection/blob/master/README_IMG/baseline%E6%A8%A1%E5%9E%8BRetinanet.jpg)
[baseline模型RetinaNet](https://tianchi.aliyun.com/forum/postDetail?spm=5176.12282027.0.0.6a44379c8d3XzW&postId=80827)  
baseline模型推理情况：分割小图尺寸：800x800，2张P100卡，单线程运行，400步长重叠滑窗分割，1张原片3-4分钟。  
  
  
### 2019年11月6日

#### 主体内容
1. Faster-RCNN实验2主要是研究**滑窗分割测试集原图的步长**，在LeaderBoard的结果如下：

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|stride=768|0.1010|0.1097|0.0922|7|10|
|stride=768*(3/4)|0.1241|0.1306|0.1176|7|24|

注: 此刻用的CONF_THRESH=0.5和NMS_THRESH = 0.1输出结果。

总结：**stride越小当然越好**，但对于Faster-RCNN来说，Stride=768/2最后会使得预测一张原片要24分钟左右，因此才选择3/4的768做实验。当stride=768时，一共有601,424张分割小图（58.7GB）。当stride=768*(3/4)时，一共有1,072,553张分割小图（109.9GB）。当stride=768*(1/2)时，一共有 张分割小图（192.3GB）。如果像RetinaNet这种模型复杂度不高的模型可以考虑像官方提出的原图尺寸/2来滑动预测。
  
    
### 2019年11月7日
#### 主体内容
1. Faster-RCNN实验3主要是研究**随个体变化随机性强的数据集**，在LeaderBoard的结果如下： 

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|中心固定86波动范围下的数据集|0.1241|0.1306|0.1176|7|24|
|随个体变化随机性强的数据集|0.1412|0.1473|0.1352|7|24|  

注：此刻用的CONF_THRESH=0.5，NMS_THRESH = 0.1，STRIDE=int(768*(3/4))。 

总结：该对比实验证实了2019年11月3日实验记录第二点关于数据集的考虑是正确的，因此**建议接下来使用随个体变化随行性强的新数据集作为接下来的训练集**，同时也在一定程度上说明数据随机性对于模型性能提升的帮助，后续可以考虑加入数据增强看是否还能够提升模型表现。

### 2019年11月9日
#### 主体内容
1. Faster-RCNN实验4主要是研究**Online Hard Example Mining (OHEM)**,在LeaderBoard的结果如下： 

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|VGG16|0.1412|0.1473|0.1352|7|24|  
|VGG16_OHEM|0.1394|0.1456|0.1333|7|24|  

注：此刻用的CONF_THRESH=0.5，NMS_THRESH = 0.1，STRIDE=int(768*(3/4))。 

总结：  
1.**加入OHEM结果并没有想象中好**，即Faster-RCNN在Fast-RCNN检测模块尽可能使用假阳性负样本并不能带来性能提升，这里猜测可能原因是数据集预处理时，我们并没去考虑IOU<0.6的细胞进新的pos阳性中，但实际上有可能出现2019年10月20日主体内容第二点提到的情况，那么如果重叠部分（假设IOU<0.6）内有粗大细胞核，那么该重叠部门会被模型认为是假阳性负样本，即使它本应该是正样本。而OHEM使得模型放大了这种因我们数据预处理产生的假阳性负样本（即不属于真实情况下的假阳性负样本）的情况，使得模型表现变差。这只是个人的猜测，要怎么去验证这个猜测，可能需要再做深入数据和模型研究。如果存在这个问题，数据集的预处理是不是得重新考虑怎么解决这种人为导致的假阳性样本问题。  
2. 该实验4还是把OHEM建立在含pos细胞的ROI图上，这也是
[OHEM原论文](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf)
[官方代码](https://github.com/abhi2610/ohem) 
[Faster-rcnn_ohem参考代码](https://github.com/manutdzou/py-faster-rcnn-OHEM)使用的手段, 但是关于如何将neg病理图加进来，我并没有实验，我看过Github论坛上有人把neg图放入pos图里一起训练，但好像效果不好，因此并没有尝试。  

#### 其它
1. 能实现1/2重叠滑动预测对结果帮助可能很大。因为在钉钉群里有人提到他用baseline模型（即RetinaNet）stride=800*(1/2)重叠滑动预测的分数是1.8, 而stride=800*(3/4)下是0.09。因此one-stage模型速度快耗内存小的优势在这就很好的体现出来了，但two-stage模型并不是说就不好，因为Faster-RCNN在stride=768*(3/4)下是0.14，只不过耗计算机资源所以才不同实现stride=768*(1/2)。这里给后续选择模型的一个建议就是：    
(1) 如果选two-stage要看：速度>mAP;  
(2) 如果选one-stage要看：mAP>速度;  
2. [宫颈病变细胞的分类及特点](https://tianchi.aliyun.com/forum/postDetail?spm=5176.12586969.1002.15.76de7611561Ea7&postId=80247) 论文可以看出病变细胞主要反映在核质比和细胞质染色深。另外评论区提到数据的漏标的问题，也即假阳性负样本的问题，所以OHEM慎重使用。  
3. Baseline模型中data_loader.py里使用了跟我们类似的获取patch的方法，不过区别在于baseline用的overlap_threshold是0.5，我们用的是0.6且我们考虑了绝对相交面积大的影响。此外，Baseline模型在augmentation.py中使用了三种数据增强方式：水平翻转，垂直翻转和90度旋转。  

### 2019年11月12日
#### 主体内容
1. Faster-RCNN实验5主要是研究**抽取特征图的预训练模型**,在LeaderBoard的结果如下： 

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|VGG16|0.1412|0.1473|0.1352|7|24|  
|ResNet50|0.1554|0.1623|0.1484|8|39|  

注：此刻用的CONF_THRESH=0.5，NMS_THRESH = 0.1，STRIDE=int(768*(3/4))。 

总结：**复杂度更高的预训练模型能提高结果分数**，但由于改用Resnet50的模型在预测时单进程就占了GPU百分之65-70的空间，导致无法像之前VGG16做预训练模型时能用4个进程同时进行预测，因此只能单进程预测使得预测时间变长了。现有显卡条件不推荐使用Restnet101。  

### 2019年11月14日
#### 主体内容
1. Faster-RCNN实验6主要是研究**传统数据增强（增加垂直翻转和旋转）**,在LeaderBoard的结果如下： 

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|水平翻转|0.1554|0.1623|0.1484|8|39|  
|水平/垂直翻转+逆时针90度旋转|0.1579|0.1633|0.1525|8|41|  

注：此刻用的CONF_THRESH=0.5，NMS_THRESH = 0.1，STRIDE=int(768*(3/4))。  

总结：**增加额外传统数据增强手段提升不是特别大**。  

### 2019年11月17日
#### 主体内容
1. Faster-RCNN实验7主要是研究**加入额外的数据（用全部数据进行训练且加入另一组新产生的数据集）**,在LeaderBoard的结果如下： 

|Hyperparameter|Score|mAP@0.3|mAP@0.5|Training Hours|Predicting Hours|
|:---:|:---:|:---:|:---:|:---:|:---:|
|train数据集训练|0.1579|0.1633|0.1525|8|41|  
|train+valid+new数据集训练|0.1881|0.1942|0.1819|8|41| 

注：此刻用的CONF_THRESH=0.5，NMS_THRESH = 0.1，STRIDE=int(768*(3/4))。  

总结：**用完整的数据集训练提升很大**，原来模型训练一直是用划分后的训练集（4282张图片）训练，但其实valid验证集还有756张没有用于模型的训练，实验7这次就是把验证集的数据和另外一组新产生的数据集（5037张）加入到原有训练集单中输入到模型里，这样训练集一共是10075张训练图像，获得的提升还是蛮大的。  
